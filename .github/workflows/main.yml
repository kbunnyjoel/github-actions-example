name: Nodejs CI with code coverage

on:
  workflow_dispatch:
    inputs:
      destroy:
        description: 'Set to true to destroy the EKS cluster'
        required: false
        default: 'false'
      run_terraform:
        description: 'Run Terraform? (true/false)'
        required: false
        default: 'true'

  push:
    branches: [ main ]
  pull_request:
    branches: [ main, 'feature/*' ]

jobs:
  buil-and-test:
    runs-on: ubuntu-latest

    env:
      NUMBER1: ${{ github.event.inputs.number1 }}
      NUMBER2: ${{ github.event.inputs.number2 }}

    strategy:
      matrix:
        node-version: [20.x]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: List files in workspace
        run: ls -l

      - name: Use Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run tests and collect coverage
        run: npm test

      - name: Debug input values
        run: |
          echo "NUMBER1=${NUMBER1}"
          echo "NUMBER2=${NUMBER2}"
        env:
          NUMBER1: ${{ github.event.inputs.number1 }}
          NUMBER2: ${{ github.event.inputs.number2 }}

      - name: Start Node server in background
        run: |
          npm start &
        env:
          INPUT_NUMBER1: ${{ github.event.inputs.number1 }}
          INPUT_NUMBER2: ${{ github.event.inputs.number2 }}

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-node-${{ matrix.node-version }}
          path: coverage/

  docker:
    name: Build and push Docker image
    runs-on: ubuntu-latest
    permissions:
      packages: write
    needs: buil-and-test
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: GHCR login
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Extract short SHA
        id: vars
        run: echo "sha_short=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT

      - name: Container Registry push image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ${{ secrets.DOCKER_USERNAME }}/my-node-app:${{ github.sha }}
            ghcr.io/${{ github.repository_owner }}/my-node-app:${{ github.sha }}

      - name: Run Docker container in background
        run: docker run -d -p 3000:3000 --name live-app ${{ secrets.DOCKER_USERNAME }}/my-node-app:${{ github.sha }}

      - name: Replace image tag with Git SHA
        run: |
          sed -i "s|__BUILD_SHA__|${{ github.sha }}|g" k8s/deployment/deployment.yaml

      - name: Wait for app to be ready
        run: |
          for i in {1..10}; do
            curl --fail http://localhost:3000/status && exit 0
            sleep 2
          done
          echo "App did not become ready" && exit 1

  terraform-eks:
    if: ${{ github.event.inputs.run_terraform == 'true' }}
    runs-on: ubuntu-latest
    needs: docker
    defaults:
      run:
        working-directory: terraform
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-southeast-2

      - name: Install Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.11.0
      
      - name: Terraform Init
        working-directory: terraform
        run: terraform init

      # - name: Terraform Unlock
      #   run: terraform force-unlock -force 17e8de4f-d48a-dd7a-825a-b76d390468d0

      - name: Terraform Validate
        run: terraform validate
      - name: Terraform Format
        run: terraform fmt -check
      
      - name: Terraform Plan
        run: terraform plan

      - name: Terraform Apply
        working-directory: terraform
        if: github.event.inputs.destroy != 'true'
        run: terraform apply -auto-approve
      
      - name: Upload deployment_key.pem as artifact
        uses: actions/upload-artifact@v4
        with:
          name: deployment-key
          path: terraform/keys/deployment_key.pem

      - name: Terraform Destroy
        if: github.event.inputs.destroy == 'true'
        run: terraform destroy -auto-approve
          
      - name: Install kubectl and check EKS status
        if: github.event.inputs.destroy != 'true'
        run: |
          set -e
          VERSION=v1.33.1
          echo "Installing kubectl version: $VERSION"
          curl -fsSL -o kubectl "https://dl.k8s.io/release/${VERSION}/bin/linux/amd64/kubectl"
          chmod +x kubectl && sudo mv kubectl /usr/local/bin/

          aws eks update-kubeconfig --region ap-southeast-2 --name github-actions-eks-example

          echo "Checking Kubernetes nodes..."
          kubectl get nodes
          echo "Checking component statuses..."
          kubectl get componentstatuses
          echo "Listing kube-system pods..."
          kubectl get pods -n kube-system
      
  deploy-argocd:
    if: github.event.inputs.run_terraform == 'true' && github.event.inputs.destroy != 'true'
    needs: terraform-eks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-southeast-2
      - name: Configure kubectl for EKS
        run: |
          aws eks update-kubeconfig --region ap-southeast-2 --name github-actions-eks-example
      - name: Wait for EKS API and nodes to be ready
        run: |
          echo "Waiting for Kubernetes API..."
          for i in {1..30}; do
            kubectl version && break || sleep 10
          done
          echo "Waiting for at least one node to be Ready..."
          for i in {1..30}; do
            kubectl get nodes | grep -q ' Ready ' && break || sleep 10
          done

      - name: Install Argo CD
        run: |
          echo "Installing ArgoCD..."
          kubectl create namespace argocd || true
          kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
          
          echo "Checking ArgoCD pods status..."
          kubectl get pods -n argocd
          
          echo "Proceeding without waiting for ArgoCD server to be ready"
      
      - name: Apply ArgoCD LoadBalancer Service
        run: kubectl apply -f k8s/argocd/argocd-svc.yaml

      - name: Wait for ArgoCD LoadBalancer
        run: |
          echo "Waiting for ArgoCD LoadBalancer to be provisioned..."
          for i in {1..30}; do
            LB_HOSTNAME=$(kubectl get svc argocd-server-lb -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null)
            if [ ! -z "$LB_HOSTNAME" ]; then
              echo "ArgoCD LoadBalancer found: $LB_HOSTNAME"
              break
            fi
            echo "Waiting for ArgoCD LoadBalancer to be provisioned... (attempt $i/30)"
            sleep 10
          done

      - name: Update ArgoCD DNS record
        run: |
          # Get the LoadBalancer hostname
          LB_HOSTNAME=$(kubectl get svc argocd-server-lb -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          
          if [ -z "$LB_HOSTNAME" ]; then
            echo "Error: ArgoCD LoadBalancer not found"
            exit 1
          fi
          
          echo "ArgoCD LoadBalancer hostname: $LB_HOSTNAME"
          
          # Resolve the LoadBalancer hostname to an IP
          LB_IP=$(dig +short $LB_HOSTNAME | head -n 1)
          
          if [ -z "$LB_IP" ]; then
            echo "Error: Could not resolve LoadBalancer hostname to IP"
            exit 1
          fi
          
          echo "ArgoCD LoadBalancer IP: $LB_IP"
          
          # Get the Route53 hosted zone ID
          ZONE_ID=$(aws route53 list-hosted-zones --query "HostedZones[?Name=='joel.cloud.'].Id" --output text | sed 's/\/hostedzone\///')
          
          # Update the Route53 record
          aws route53 change-resource-record-sets --hosted-zone-id $ZONE_ID --change-batch '{
            "Changes": [
              {
                "Action": "UPSERT",
                "ResourceRecordSet": {
                  "Name": "argocd.joel.cloud",
                  "Type": "A",
                  "TTL": 60,
                  "ResourceRecords": [
                    {
                      "Value": "'$LB_IP'"
                    }
                  ]
                }
              }
            ]
          }'
          
          echo "DNS record updated for argocd.joel.cloud -> $LB_IP"
          
      - name: Check and update EKS node security group
        run: |
          SG_ID="sg-0b8ab3f7f818243fd"  # Your EKS node security group ID
          echo "Checking if security group allows inbound traffic on port 8080..."
          
          # Check if the rule exists
          RULE_EXISTS=$(aws ec2 describe-security-groups --group-ids $SG_ID --query "SecurityGroups[0].IpPermissions[?FromPort==\`8080\` && ToPort==\`8080\` && IpProtocol==\`tcp\`]" --output text)
          
          if [ -z "$RULE_EXISTS" ]; then
            echo "Adding rule to allow inbound traffic on port 8080..."
            aws ec2 authorize-security-group-ingress \
              --group-id $SG_ID \
              --protocol tcp \
              --port 8080 \
              --cidr 0.0.0.0/0
            echo "Rule added successfully"
          else
            echo "Rule already exists"
          fi

      - name: Check ArgoCD status
        run: |
          echo "Checking ArgoCD service..."
          kubectl get svc -n argocd
          
          echo "Checking ArgoCD pods..."
          kubectl get pods -n argocd
          
          echo "Checking ArgoCD server pod details..."
          ARGOCD_POD=$(kubectl get pods -n argocd -l app.kubernetes.io/name=argocd-server -o name | head -n 1)
          if [ ! -z "$ARGOCD_POD" ]; then
            kubectl describe pod -n argocd ${ARGOCD_POD#*/}
          fi
          
          echo "Getting ArgoCD admin password..."
          kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d || echo "Initial admin secret not found"

      - name: Test direct access to LoadBalancer
        run: |
          LB_HOSTNAME=$(kubectl get svc argocd-server-lb -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          echo "Testing HTTP access to $LB_HOSTNAME..."
          curl -v --max-time 10 http://$LB_HOSTNAME || echo "HTTP access failed"
          echo "Testing HTTPS access to $LB_HOSTNAME..."
          curl -v -k --max-time 10 https://$LB_HOSTNAME || echo "HTTPS access failed"
