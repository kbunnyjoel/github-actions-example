name: Nodejs CI with code coverage

on:
  workflow_dispatch:
    inputs:
      destroy:
        description: 'Set to true to destroy the EKS cluster'
        required: false
        default: 'false'
      run_terraform:
        description: 'Run Terraform? (true/false)'
        required: false
        default: 'true'

  push:
    branches: [ main ]
  pull_request:
    branches: [ main, 'feature/*' ]

jobs:
  buil-and-test:
    runs-on: ubuntu-latest

    env:
      NUMBER1: ${{ github.event.inputs.number1 }}
      NUMBER2: ${{ github.event.inputs.number2 }}

    strategy:
      matrix:
        node-version: [20.x]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: List files in workspace
        run: ls -l

      - name: Use Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run tests and collect coverage
        run: npm test

      - name: Debug input values
        run: |
          echo "NUMBER1=${NUMBER1}"
          echo "NUMBER2=${NUMBER2}"
        env:
          NUMBER1: ${{ github.event.inputs.number1 }}
          NUMBER2: ${{ github.event.inputs.number2 }}

      - name: Start Node server in background
        run: |
          npm start &
        env:
          INPUT_NUMBER1: ${{ github.event.inputs.number1 }}
          INPUT_NUMBER2: ${{ github.event.inputs.number2 }}

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-node-${{ matrix.node-version }}
          path: coverage/

  docker:
    name: Build and push Docker image
    runs-on: ubuntu-latest
    permissions:
      packages: write
    needs: buil-and-test
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: GHCR login
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Extract short SHA
        id: vars
        run: echo "sha_short=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT

      - name: Container Registry push image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ${{ secrets.DOCKER_USERNAME }}/my-node-app:${{ github.sha }}
            ghcr.io/${{ github.repository_owner }}/my-node-app:${{ github.sha }}

      - name: Run Docker container in background
        run: docker run -d -p 3000:3000 --name live-app ${{ secrets.DOCKER_USERNAME }}/my-node-app:${{ github.sha }}

      - name: Replace image tag with Git SHA
        run: |
          sed -i "s|__BUILD_SHA__|${{ github.sha }}|g" k8s/deployment/deployment.yaml

      - name: Wait for app to be ready
        run: |
          for i in {1..10}; do
            curl --fail http://localhost:3000/status && exit 0
            sleep 2
          done
          echo "App did not become ready" && exit 1

  terraform-eks:
    if: ${{ github.event.inputs.run_terraform == 'true' }}
    runs-on: ubuntu-latest
    needs: docker
    defaults:
      run:
        working-directory: terraform
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-southeast-2

      - name: Install Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.11.0
      
      - name: Terraform Init
        working-directory: terraform
        run: terraform init

      # - name: Terraform Unlock
      #   run: terraform force-unlock -force 17e8de4f-d48a-dd7a-825a-b76d390468d0

      - name: Terraform Validate
        run: terraform validate
      - name: Terraform Format
        run: terraform fmt -check
      
      - name: Terraform Plan
        run: terraform plan

      - name: Terraform Apply
        working-directory: terraform
        if: github.event.inputs.destroy != 'true'
        run: terraform apply -auto-approve
      
      - name: Upload deployment_key.pem as artifact
        uses: actions/upload-artifact@v4
        with:
          name: deployment-key
          path: terraform/deployment_key.pem

      - name: Terraform Destroy
        if: github.event.inputs.destroy == 'true'
        run: terraform destroy -auto-approve
          
  #  aws eks update-kubeconfig --region ap-southeast-2 --name github-actions-eks-example
      - name: Install kubectl and check EKS status
        if: github.event.inputs.destroy != 'true'
        run: |
          set -e
          VERSION=v1.33.1
          echo "Installing kubectl version: $VERSION"
          curl -fsSL -o kubectl "https://dl.k8s.io/release/${VERSION}/bin/linux/amd64/kubectl"
          chmod +x kubectl && sudo mv kubectl /usr/local/bin/

          aws eks update-kubeconfig --region ap-southeast-2 --name github-actions-eks-example

          echo "Checking Kubernetes nodes..."
          kubectl get nodes
          echo "Checking component statuses..."
          kubectl get componentstatuses
          echo "Listing kube-system pods..."
          kubectl get pods -n kube-system
      
  deploy-argocd:
    if: github.event.inputs.run_terraform == 'true' && github.event.inputs.destroy != 'true'
    needs: terraform-eks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-southeast-2
      - name: Configure kubectl for EKS
        run: |
          aws eks update-kubeconfig --region ap-southeast-2 --name github-actions-eks-example
      - name: Wait for EKS API and nodes to be ready
        run: |
          echo "Waiting for Kubernetes API..."
          for i in {1..30}; do
            kubectl version && break || sleep 10
          done
          echo "Waiting for at least one node to be Ready..."
          for i in {1..30}; do
            kubectl get nodes | grep -q ' Ready ' && break || sleep 10
          done
      - name: Install cert-manager
        run: |
          echo "Installing cert-manager..."
          kubectl apply --validate=false -f k8s/argocd/cert-manager.yaml
          kubectl rollout status deployment/cert-manager -n cert-manager --timeout=180s

      - name: Wait for cert-manager readiness
        run: |
          kubectl wait --for=condition=Available --timeout=180s deployment/cert-manager -n cert-manager
          kubectl wait --for=condition=Available --timeout=180s deployment/cert-manager-webhook -n cert-manager
          kubectl wait --for=condition=Available --timeout=180s deployment/cert-manager-cainjector -n cert-manager

      - name: Install Argo CD
        run: |
          kubectl create namespace argocd || true
          kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

      - name: Apply ClusterIssuer
        run: kubectl apply -f k8s/argocd/argocd-certissuer.yaml

      - name: Apply Argo CD Ingress
        run: |
          kubectl apply -f k8s/argocd/argocd-ingress.yaml
      
      - name: Get Ingress SVC
        run: kubectl get svc -n argocd argocd-server -o yaml
      - name: Get ArgoCD External IP and save output
        id: get-ip
        run: |
          IP=$(kubectl get svc argocd-server -n argocd -o jsonpath="{.spec.clusterIP}")
          if [ -z "$IP" ]; then
            echo "ArgoCD service IP not found. Exiting."
            exit 1
          fi
          echo "ArgoCD service IP: $IP"
          # Save the IP to GitHub Actions output
          echo "argocd_ip=$IP" >> $GITHUB_OUTPUT
      
      - name: Apply ArgoCD LoadBalancer Service
        run: kubectl apply -f k8s/argocd/argocd-svc.yaml

      - name: Update ArgoCD DNS record
        run: |
          # Get the LoadBalancer hostname
          LB_HOSTNAME=$(kubectl get svc argocd-server-lb -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          
          if [ -z "$LB_HOSTNAME" ]; then
            echo "Error: ArgoCD LoadBalancer not found"
            exit 1
          fi
          
          echo "ArgoCD LoadBalancer hostname: $LB_HOSTNAME"
          
          # Resolve the LoadBalancer hostname to an IP
          LB_IP=$(dig +short $LB_HOSTNAME | head -n 1)
          
          if [ -z "$LB_IP" ]; then
            echo "Error: Could not resolve LoadBalancer hostname to IP"
            exit 1
          fi
          
          echo "ArgoCD LoadBalancer IP: $LB_IP"
          
          # Get the Route53 hosted zone ID
          ZONE_ID=$(aws route53 list-hosted-zones --query "HostedZones[?Name=='joel.cloud.'].Id" --output text | sed 's/\/hostedzone\///')
          
          # Update the Route53 record
          aws route53 change-resource-record-sets --hosted-zone-id $ZONE_ID --change-batch '{
            "Changes": [
              {
                "Action": "UPSERT",
                "ResourceRecordSet": {
                  "Name": "argocd.joel.cloud",
                  "Type": "A",
                  "TTL": 60,
                  "ResourceRecords": [
                    {
                      "Value": "'$LB_IP'"
                    }
                  ]
                }
              }
            ]
          }'
          
          echo "DNS record updated for argocd.joel.cloud -> $LB_IP"
